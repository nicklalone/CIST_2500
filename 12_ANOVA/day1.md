One of my favorite quotes about humanity is from an old sociologist named Gabriel Tarde. He was a judge in Germany and was a major opponent of Emile Durkheim. This conflict was one of the last salvos between folks who sided with Newton (Durkheim) and folks who sided with Leibniz (Tarde).

The reason I bring this up is that the outcome of these two is why we discuss statistics the way that we do. At our core, being objective about evaluating humans is something interesting that comes out of this. Durkheim believed we could (and won) while Tarde believed we could not (and he's beginning to win now). 

So the quote is this: 

> _"To exist is to differ; difference is, in a sense, the truly substantial side of things; it is at once their ownmost possession and that which they hold most in common. This must be our starting point, and we must refrain from further explaining this principle."

Humans are wildly varied. Whereas Durkheim believed that we could objectively understand society as an entity that directed our actions, Tarde believed that it was an entity that is manifested 1 interaction at a time. While it was easier to do what Durkheim wanted first, Tarde's proving to have a bit more foresight.

Humans are varied. Infinitely varied. And the source of that variance is a combination of biology, social, and environmental influences. Sometimes, our data is varied because the sample of humans we grabbed is itself infinitely varied. 

There's a test for this!

And it has its uses. We call it "Analysis of Variance" or ANOVA. 

We can define [ANOVA](https://www.scribbr.com/statistics/one-way-anova/) as: 

>"a statistical test used to analyze the difference between the means of more than two groups. A one-way ANOVA uses one independent variable, while a two-way ANOVA uses two independent variables."

So rather than look for statistical significance, we're essentially looking at a test that lets us look at how we vary from each other on various types of issues. This is different than what we're looking at with means, medians, and modes. We aren't looking for where we least agree, we're looking for how we disagree, agree, and then maybe infer Why or How.

---------------- Table of Contents ---------------- 

1. [Types of Statistical Studies](#types)
2. [What is ANOVA.](#ANOVA)
3. [A List of Ingredients]() 
4. [Formulas](#formulas)
5. [Hypotheses in ANOVA](#hype)
   
5. [Experiment Design](#experi)
	* [Intro](#intro)
	* [Randomized](#random)
	* [Multiple](#multi)
	* [Random Block](#random)

---------------- Table of Contents ---------------- 

## <a id="types"></a> Types of Statistical Studies


## <a id = "ANOVA"></a> What is ANOVA?

## <a id="ingredients"></a> Ingredients

* ***ANOVA table**: A table used to summarize the analysis of variance computations and results. It contains columns showing the source of variation, the sum of squares, the degrees of freedom, the mean square, the F value(s), and the p-value(s).

* **Blocking:** The process of using the same or similar experimental units for all treatments. The purpose of blocking is to remove a source of variation from the error term and hence provide a more powerful test for a difference in population or treatment means.

* **Comparisonwise Type I error rate:** The probability of a Type I error associated with a single pairwise comparison.

* **Completely randomized design:** An experimental design in which the treatments are randomly assigned to the experimental units.

* **Experimental statistical study:** A study in which the investigator controls the values of one or more variables believed to be related to the outcome of interest, and then measures and records the outcome. The investigator’s control over the values of variables believed to be related to the outcome of interest allows for possible conclusions about whether any of the manipulated variables might have a cause-and-effect relationship with the outcome.

* **Experimental units:** The objects of interest in the experiment.

* **Experimentwise Type I error rate:** The probability of making a Type I error on at least one of several pairwise comparisons.

* **Factor:** Another word for the independent variable of interest.

* **Factorial experiment:** An experimental design that allows simultaneous conclusions about two or more factors.

* **Interaction:** The effect produced when the levels of one factor interact with the levels of another factor in influencing the response variable.

* **Multiple comparison procedures:** Statistical procedures that can be used to conduct statistical comparisons between pairs of population means.

* **Observational study:** A study in which the investigator observes the outcome of interest and possibly values of one or more variables believed to be related to the outcome without controlling the values of any variables, and then measures and records the outcome. The investigator’s lack of control over the values of variables believed to be related to the outcome of interest allows only for possible conclusions about associations between the outcome and the variables.

* **Partitioning:** The process of allocating the total sum of squares and degrees of freedom to the various components.

* **Randomized block design:** An experimental design employing blocking.

* **Replications:** The number of times each experimental condition is repeated in an experiment.

* **Response variable:** Another word for the dependent variable of interest.

* **Single-factor experiment:** An experiment involving only one factor with k populations or treatments.

* **Treatments:** Different levels of a factor.

## <a id = "formulas"></a> Formulas
![Formulas 1](/images/ANOVA-1.png)
![Formulas 1](/images/ANOVA-2.png)

## <a id="hype"></a> Hypotheses in ANOVA

## <a id="experi"></a> Experiment Design

### <a id="intro"></a> Intro

### <a id = "random"></a> Randomized

### <a id = "multi"></a> Multiple

### <a id = "random"></a> Random Block

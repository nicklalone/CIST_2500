---------------- Table of Contents ---------------- 

1. [Regression](#regr)

3. [What is Regression?](#whatis)
4. [A List of Ingredients](#ingred) 
5. [Formulas](#formulas)
6. [Hypotheses in Regression](#hype)
   
5. [Types of Regression](#types)
	* [Simple Linear Regression](#slr)
	* [Multiple Regression](#multi)
	* [Logistic Regression](#logis)

6. [Components](#comp)
	* [Dependent Variables](#dv)
	* [Independent Variables](#iv)
	* [Least Squares](#least)
	* [Coefficient of Determination](#coef)

7.  [Outliers and Other Data Issues](#outliers)

---------------- Table of Contents ---------------- 

## <a id="regr"></a> Regression

## <a id="whatis"></a> What is Regression?
## <a id="ingred"></a> A List of Ingredients 

* ***ANOVA table:** The analysis of variance table used to summarize the computations associated with the F test for significance.

* **Coefficient of determination:** A measure of the goodness of fit of the estimated regression equation. It can be interpreted as the proportion of the variability in the dependent variable y that is explained by the estimated regression equation.

* ***Confidence interval:** The interval estimate of the mean value of y for a given value of x.

* ***Correlation coefficient:** A measure of the strength of the linear relationship between two variables (previously discussed in Chapter 3).

* ***Dependent variable:** The variable that is being predicted or explained. It is denoted by y.

* **Estimated regression equation:** The estimate of the regression equation developed from sample data by using the least squares method. For simple linear regression, the estimated regression equation is y⁄ 5 b0 1 b1x.

* ***High leverage points:** Observations with extreme values for the independent variables. Independent variable The variable that is doing the predicting or explaining. It is denoted by x.

* **Influential observation:** An observation that has a strong influence or effect on the regression results.

* ****i*th residual:** The difference between the observed value of the dependent variable and the value predicted using the estimated regression equation; for the ith observation the ith residual is yi 2 y⁄i.

* **Least squares method:** A procedure used to develop the estimated regression equation. The objective is to minimize o( yi 2 y⁄i)2.

* **Mean square error:** The unbiased estimate of the variance of the error term 2. It is denoted by MSE or s2.

* **Normal probability plot:** A graph of the standardized residuals plotted against values of the normal scores. This plot helps determine whether the assumption that the error term has a normal probability distribution appears to be valid.

* **Outlier:** A data point or observation that does not fit the trend shown by the remaining data.

* **Prediction interval:** The interval estimate of an individual value of y for a given value of x.

* **Regression equation:** The equation that describes how the mean or expected value of the dependent variable is related to the independent variable; in simple linear regression, E( y) 5 b0 1 b1x.

* **Regression model:** The equation that describes how y is related to x and an error term; in simple linear regression, the regression model is y 5 b0 1 b1x 1 e.

* **Residual analysis:** The analysis of the residuals used to determine whether the assumptions made about the regression model appear to be valid. Residual analysis is also used to identify outliers and influential observations.

* **Residual plot:** Graphical representation of the residuals that can be used to determine whether the assumptions made about the regression model appear to be valid.

* **Scatter diagram:** A graph of bivariate data in which the independent variable is on the horizontal axis and the dependent variable is on the vertical axis.

* **Simple linear regression:** Regression analysis involving one independent variable and one dependent variable in which the relationship between the variables is approximated by a straight line.

* **Standard error of the estimate:** The square root of the mean square error, denoted by s. It is the estimate of , the standard deviation of the error term e.

* **Standardized residual:** The value obtained by dividing a residual by its standard deviation.

## <a id="formulas"></a> Formulas

![Regression 1](/images/reg-1.png)

![Regression 2](/images/reg-2.png)
![Regression 3](/images/reg-3.png)

## <a id="hype"></a> Hypotheses in Regression
   
## <a id="types"></a> Types of Regression
### <a id="slr"></a> Simple Linear Regression
### <a id="multi"></a> Multi-Regression
### <a id="logis"></a> Logistic Regression

## <a id="comp"></a> Components
### <a id="least"></a> Least Squares
### <a id="coef"></a> Coefficient of Determination

### <a id="outliers"></a> Outliers and Other Data Issues
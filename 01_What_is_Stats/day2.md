---------------- Table of Contents ---------------- 

1. [Fun Things Stats Has Done](#fun)
2. [How Does Statistics Work?](#howwork)
3. [Description](#describe)
4. [Comparison](#compare)
5. [Relation](#relate)

---------------- Table of Contents ---------------- 

## <a id="fun"></a>Fun Things Stats Has Done


## <a id="howwork"></a>How Does Statistics Work?
So you may ask yourself.

![The Process](/images/process.png)

## <a id="howwork"></a>Describe
Descriptives essentially take pieces of data and refine it in such a way as to turn it into information we can use. We tend to begin with a number of measures sometimes referred to as summary stats or modes of central tendency: (mean, median, range, and standard deviation). 

Mean is the average, median is the middle most point, range is lowest to highest value, and standard deviation describes how much variance is within the set of data. Think of it sort of like a weather person talking about average temperatures, what the high and low will be, how today differed from yesterday but also the same day last year. 

While these data are useful, folks will tend to react to raw values in different ways. As such, there are also ways to show these values graphically by using things like Boxplots, histograms, pie charts, Pareto charts, and many others. One last way to think about these descriptives or summary stats is that they show us what sort of distribution we have (i.e., Poisson, binomial, normal). In the end, we cannot really make inferences from here, not actual ones anyway. We can make useful guesses as to trends, but we need more methods to take us from description to inference. 

## <a id="compare"></a> Comparison
The ability to compare things is one of the most useful skills in the Six Sigma body of knowledge. In project work, comparative experiments are used to validate whether a project was successful or not. At least two checks are regularly made to validate projects: First, did the team shift the mean of the main pain project metric? Second, did the team decrease the variability of the main pain project metric? Other uses for comparative experiments are to stratify data, validate relationships and check control groups.

Even though many different types of comparative experiments exist, it is useful to remember that comparative experiments answer only one question, “Did I make a difference?” To answer this question, hypotheses are proposed, assumptions made, samples drawn from one or more populations, test statistics calculated and decisions made. Often a stepwise procedure is employed and it is the same for any comparative experiment: one recipe to answer one question. The only place to mess this up is to pick the wrong test. Therefore, a project team should find a good comparative experiment decision tree to help decide which test to use.

In the weather example, a viewer could explore whether it is more likely to rain in March or April, whether two different TV stations make different predictions, and so forth.

## <a id="relate"></a> Relation
Relating things to one another – in other words, discovering and exploring relationships – helps in understanding and ultimately in establishing predictive models. Relational statistics break up into two broad categories: historical studies and designed experiments. Historical data is analyzed with regression and is comprised of correlations and regression. Correlations ask, “How do two things vary together? Is there a correlation between humidity and rainfall?” Regression asks, “How well can you predict one thing if you know other characteristics?” Designed experiments negate problems with regression with good research methods but require greater planning and execution skills. It may help to think of design of experiments (DOE) as active and regression as passive. DOE explores cause-and-effect relationships between and amongst many variables and also generates prediction models. For example, if a cloud is seeded with compounds X, Y and Z, then how much will it rain? In summary, both DOE and regression are focused on creating predictive models to make better data-based decisions.
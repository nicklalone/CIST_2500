# Week 7 - Sampling and Sampling Things
We have been exploring conceptual data and a variety of concepts in and around the philosophy of statistical inference. Now that we have explored how to explore the shape of our data, let's move a little further in to look within that shape and to compare it to the expected shape of the standard normal curve. 

You may ask yourself how and why such a thing matters. This is a good question.

It matters for basically 1 reason, without the laws in and around the normal curve, all of frequentist statistics couldn't be trusted. 

There are implications for this. 1. We can predict human activities to a certain extent. 2. To predict those things, we need to have a critical mass of data. 3. Our samples have issues but as long as we mind those issues, we can make inferences about human activity (or whatever we're collecting data about).

Since samples are so important, we're going to spend some time adding some new ideas. 

Every single time we take a sample and use it to understand a population, we're making estimates, we're doing probabilities. Everything begins with 2 things: 
1. What is the experiment (Another way to say this is, 'what is our research question?' More on these next week!)?
1. What is our sampling approach?

In this part of the class, we're going to concentrate not on the experiment, but on the sampling approach. We need to learn approaches to collecting data so that we can learn approaches to writing hypotheses we can solve with those sampling methods. 

---------------- Table of Contents ---------------- 

1. [Point Estimation](#pe)
	* Parameter vs Statistic(#pvs)
1. [Population Type](#pt)
1. [Data Frames](#df)
1. [Sampling Types](#st)
	* [Simple Random Sample](#srs)
	* [Random Sample](#rs)
	* [Stratified Random Sampling](#strs)
	* [Cluster Sampling](#cs)
	* [Systematic Sampling](#ss)
	* [Convenience Sampling](#cons)
	* [Judgement Sampling](#js)
1. [Differences Between Finite and Infinite Populations](#fin-infin)
1. [Samping Error](#samper)

---------------- Table of Contents ---------------- 

## <a id="pe"></a>Point Estimation

In general, we can say that within frequentist statistics we can generally do 2 things, describe and make an inference. In this section of class, we will be generally approaching single values and those single values are called Point Estimates. In the future, we will be taking this idea of point estimation and expand it into, "interval estimation."

We should connect this back to the normal curve since this is our home now. It is where we live. And so, one of the easiest ways to describe point estimation is to use a different definition of the same thing: central tendency. 

Do you remember calculating all of the modes of central tendency? Mean, Median, Mode? These are all estimates of population parameters.

Why? What? Huh?

These point estimations are just what we've been doing with Z-Scores. We use single points as estimates of population parameters. We are essentially offering an 'educated guess' about one aspect of the population given the sample we've collected. 

Of the different kinds of point estimation, we have: 
* Mean
* Median
* Mode
* 

### <a id="pvs"></a>Parameter vs Statistic

Before we leave point estimation, we should reiterate an important point about everything we'll do. 

We seek to understand the population's parameters. This is the whole point of statistics. We want to examine a sample of data (or population if we can get it) and make an inference about that population. We are always going to try and do this. 

And yet, the best we can do is to make an estimation of points or an estimation of interval. These are essentially, "1-point" like a mean or a z-score, or something. Or we use a confidence interval or deal with the idea that we can be more accurate by widening our interval (which in turn isn't that powerful, more on this later). 

To this, we must state two terms: 

> A **statistic** (those things we generate with sample data) will *change a lot*. For example, if I compare the average student debt of new, established, and retirement age faculty members in the US. 

> A **parameter** is what we're going for. We know through the law of large numbers, the central limit theorem, that the more samples we take, if we average those samples, that, once we got enough, we'd know the values for the population, the parameters. *Parameters do not change* once known (aside from drifting as all things do over time).

Who our population is, what our sample is, who our sample is, how to get at them, and what you want to learn from them is what we'll talk about.


## <a id="pt"></a>Population Type

We have to have a bit of a discussion about populations. Populations can be infinity and with this, you could never possibly grab an opinion or whatever from all of them. Alternatively, there are what are called, "Finite" populations or those populations within which you can know exactly how many there are. 

## <a id="df"></a>Data Frames

## <a id="st"></a>Sampling Types

### <a id="srs"></a>Simple Random Sample

### <a id="rs"></a>Random Sample

### <a id="strs"></a>Stratified Random Sampling

### <a id="cs"></a>Cluster Sampling

### <a id="ss"></a>Systematic Sampling

### <a id="cons"></a>Convenience Sampling

### <a id="js"></a>Judgement Sampling

## <a id="fin-infin"></a>Differences Between Finite and Infinite Populations

## <a id="samper"></a>Sampling Error


